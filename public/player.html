<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<title>Boombox • Zen</title>
<meta name="viewport" content="width=device-width,initial-scale=1"/>
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css"/>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.1/font/bootstrap-icons.css"/>
<link rel="stylesheet" href="/styles.css"/>
</head>
<body>
<div class="particles" id="particles"></div>

<nav class="navbar navbar-light bg-light shadow-sm">
  <div class="container">
    <a class="btn btn-link" href="/"><i class="bi-arrow-left"></i> Back</a>
    <span class="navbar-text"><i class="bi-music-note-list mr-1"></i> Boombox</span>
  </div>
</nav>

<div class="container py-4">
  <div class="row">
    <div class="col-lg-6 mb-3">
      <div class="panel">
        <h5 class="mb-3"><i class="bi-collection"></i> Library</h5>
        <div class="input-group mb-3">
          <select class="custom-select" id="fileSelect">
            <option disabled selected>— files will appear here —</option>
          </select>
          <div class="input-group-append">
            <button id="refresh" class="btn btn-outline-secondary"><i class="bi-arrow-clockwise"></i></button>
          </div>
        </div>
        <div class="d-flex">
          <button id="play" class="btn btn-ice mr-2" disabled><i class="bi-play-fill"></i> Play</button>
          <button id="stop" class="btn btn-outline-secondary" disabled><i class="bi-stop-fill"></i> Stop</button>
        </div>
      </div>
    </div>

    <div class="col-lg-6 mb-3">
      <div class="panel">
        <h5 class="mb-3"><i class="bi-volume-up"></i> Volume</h5>
        <input type="range" class="custom-range" id="vol" min="0" max="100" value="70">
        <div class="meta mt-2"><span id="volVal">70%</span></div>
      </div>
    </div>

    <div class="col-12 mb-3">
      <div class="panel">
        <h5 class="mb-3"><i class="bi-mic"></i> Voice Control</h5>
        <div class="row">
          <div class="col-md-6">
            <div class="d-flex mb-2">
              <button id="voiceInit" class="btn btn-outline-primary mr-2">
                <i class="bi-mic"></i> Initialize Voice
              </button>
              <button id="voiceStart" class="btn btn-success mr-2" disabled>
                <i class="bi-mic-fill"></i> Start Listening
              </button>
              <button id="voiceStop" class="btn btn-danger" disabled>
                <i class="bi-mic-mute"></i> Stop Listening
              </button>
            </div>
            <div class="d-flex mb-2">
              <button id="voiceFeedback" class="btn btn-outline-info mr-2">
                <i class="bi-volume-up"></i> Toggle Feedback
              </button>
                             <button id="voiceTest" class="btn btn-outline-secondary">
                 <i class="bi-chat"></i> Test Voice
               </button>
               <button id="voiceDebug" class="btn btn-outline-warning ml-2">
                 <i class="bi-bug"></i> Debug Voice
               </button>
               <button id="voiceReset" class="btn btn-outline-danger ml-2">
                 <i class="bi-arrow-clockwise"></i> Reset Voice
               </button>
               <button id="voiceShutdown" class="btn btn-danger ml-2">
                 <i class="bi-power"></i> Shutdown Voice
               </button>
               <button id="pauseTest" class="btn btn-outline-warning ml-2">
                 <i class="bi-pause"></i> Test Pause
               </button>
            </div>
          </div>
          <div class="col-md-6">
            <div class="voice-status">
              <small class="text-muted">
                Status: <span id="voiceStatus">Not initialized</span><br>
                Listening: <span id="voiceListening">No</span><br>
                Feedback: <span id="voiceFeedbackStatus">Enabled</span>
              </small>
            </div>
            <div class="mt-2">
              <small class="text-muted">
                <strong>Voice Commands:</strong><br>
                "Play", "Pause", "Stop", "Next", "Previous"<br>
                "Volume Up", "Volume Down", "What Song", "Help"<br>
                <em>Works offline using your browser's built-in voice recognition!</em>
              </small>
            </div>
          </div>
        </div>
        <div id="voiceCommands" class="mt-2" style="display: none;">
          <div class="alert alert-info">
            <strong>Voice Command Detected:</strong> <span id="lastCommand">None</span>
          </div>
        </div>
      </div>
    </div>

    <div class="col-12">
      <div class="panel">
        <h5 class="mb-3"><i class="bi-activity"></i> VU Meter</h5>
        <canvas id="vu" height="80"></canvas>
        <audio id="ghost" preload="auto" crossorigin="anonymous"></audio>
        <div class="mt-2">
          <small class="text-muted">
            Status: <span id="audioStatus">Ready</span> | 
            Mode: <span id="audioMode">Cloud</span> | 
            File: <span id="currentFile">None</span>
          </small>
        </div>
      </div>
         </div>
   </div>
 </div>

 <!-- Footer -->
 <footer class="text-center py-4 mt-5">
   <div class="container">
     <hr class="my-3">
     <p class="text-muted mb-0">
               <strong>David and Steven's Pi Project #1</strong> | 
       <span id="currentDate"></span> | 
       <em>Powered by AI</em>
     </p>
   </div>
 </footer>

 <!-- Socket.IO client -->
 <script src="/socket.io/socket.io.js"></script>
 <script src="/scripts.js"></script>
<script>
const $ = s => document.querySelector(s);
const file = $('#fileSelect'), play=$('#play'), stopBtn=$('#stop'), vol=$('#vol'), volVal=$('#volVal');
let ghost = document.getElementById('ghost'), canvas=document.getElementById('vu'), ctx=canvas.getContext('2d');
const audioStatus = $('#audioStatus'), audioMode = $('#audioMode'), currentFile = $('#currentFile');
let audioCtx, analyser, data;

// Socket.IO connection for voice commands
let socket = null;

// Initialize Socket.IO connection
function initSocketIO() {
  try {
    socket = io();
    
    socket.on('connect', () => {
      console.log('✅ Connected to server via Socket.IO');
    });
    
    socket.on('disconnect', () => {
      console.log('❌ Disconnected from server');
    });
    
    // Listen for voice commands from the server
    socket.on('voiceCommand', (data) => {
      console.log('🎤 Voice command received from server:', data);
      
      if (data.command && data.action === 'execute') {
        // Process the voice command from the server
        handleVoiceCommand(data.command);
      }
    });
    
    socket.on('connect_error', (error) => {
      console.error('Socket.IO connection error:', error);
    });
    
  } catch (error) {
    console.error('Socket.IO initialization error:', error);
  }
}

// Update status display
function updateStatus(status, file = null) {
  audioStatus.textContent = status;
  if (file) currentFile.textContent = file;
}

// Reset audio element state
function resetAudio() {
  // Close existing audio context first
  if (audioCtx) {
    console.log('Closing audio context during reset');
    audioCtx.close();
    audioCtx = null;
    analyser = null;
    data = null;
  }
  
  // Create a completely new audio element to avoid connection issues
  const newGhost = document.createElement('audio');
  newGhost.id = 'ghost';
  newGhost.preload = 'auto';
  newGhost.crossOrigin = 'anonymous';
  newGhost.volume = 0.7;
  
  // Replace the old audio element
  ghost.parentNode.replaceChild(newGhost, ghost);
  
  // Update the global reference
  ghost = newGhost;
  
  // Re-attach event listeners
  newGhost.addEventListener('loadedmetadata', () => {
    console.log('Audio metadata loaded');
    console.log('Duration:', newGhost.duration);
    console.log('Current volume:', newGhost.volume);
  });

  newGhost.addEventListener('canplay', () => {
    console.log('Audio can play');
  });

  newGhost.addEventListener('error', (e) => {
    console.error('Audio error:', e);
    console.error('Error details:', newGhost.error);
  });
  
  console.log('Audio element completely replaced');
}

// Audio event handlers
ghost.onloadstart = () => updateStatus('Loading...');
ghost.oncanplay = () => updateStatus('Ready to play');
ghost.onplay = () => updateStatus('Playing');
ghost.onpause = () => updateStatus('Paused');
ghost.onended = () => updateStatus('Ended');
ghost.onerror = (e) => updateStatus('Error: ' + (e.message || 'Unknown error'));

// Set initial volume
ghost.volume = 0.7;

async function loadFiles(){
  try{
    const refreshBtn = document.getElementById('refresh');
    refreshBtn.disabled = true;
    refreshBtn.innerHTML = '<i class="bi-arrow-clockwise"></i>';
    
    const r = await fetch('/api/audio/files'); 
    if (!r.ok) {
      throw new Error(`Server error: ${r.status}`);
    }
    
    const list = await r.json();
    if (list && list.length > 0) {
      file.innerHTML = list.map(f=>`<option>${f}</option>`).join('');
      file.disabled = false;
    } else {
      file.innerHTML = '<option disabled>No audio files found</option>';
      file.disabled = true;
    }
  } catch (error) {
    console.error('Failed to load files:', error);
    file.innerHTML = '<option disabled>Error loading files</option>';
    file.disabled = true;
  } finally {
    const refreshBtn = document.getElementById('refresh');
    refreshBtn.disabled = false;
    refreshBtn.innerHTML = '<i class="bi-arrow-clockwise"></i>';
  }
}
document.getElementById('refresh').onclick = loadFiles;
file.onchange = e => {
  const selectedFile = e.target.value;
  const hasValidFile = selectedFile && selectedFile !== '— files will appear here —' && !selectedFile.includes('Error') && !selectedFile.includes('No audio');
  
  console.log('File change event:', selectedFile, 'Valid:', hasValidFile);
  
  play.disabled = !hasValidFile;
  stopBtn.disabled = !hasValidFile;
  
  if (hasValidFile) {
    // Reset audio element state for new file
    resetAudio();
    
    // Reset button state
    play.classList.remove('btn-success');
    play.innerHTML = '<i class="bi-play-fill"></i> Play';
    
    // Reset status
    updateStatus('Ready', selectedFile);
    
    console.log('New file selected:', selectedFile);
    console.log('Audio element after reset - src:', ghost.src, 'readyState:', ghost.readyState);
  }
};

play.onclick = async ()=>{
  const f = file.value; 
  if(!f || f === '— files will appear here —') {
    alert('Please select a file to play first');
    return;
  }
  
  console.log('Attempting to play:', f);
  console.log('Current audio src:', ghost.src);
  console.log('Current audio state:', ghost.readyState);
  
  try {
    play.disabled = true;
    play.innerHTML = '<i class="bi-hourglass-split"></i> Playing...';
    
    // Always set new source for new file (prevents caching issues)
    const newSrc = `/api/audio/stream/${encodeURIComponent(f)}`;
    console.log('Setting new source:', newSrc);
    ghost.src = newSrc;
    updateStatus('Loading...', f);
    
    // Reset audio state
    ghost.currentTime = 0;
    
    // Wait for audio to be ready
    await new Promise((resolve, reject) => {
      const onCanPlay = () => {
        console.log('Audio can play, readyState:', ghost.readyState);
        ghost.removeEventListener('canplay', onCanPlay);
        ghost.removeEventListener('error', onError);
        clearTimeout(timeoutId);
        resolve();
      };
      
      const onError = (error) => {
        console.error('Audio load error:', error);
        ghost.removeEventListener('canplay', onCanPlay);
        ghost.removeEventListener('error', onError);
        clearTimeout(timeoutId);
        reject(error);
      };
      
      ghost.addEventListener('canplay', onCanPlay);
      ghost.addEventListener('error', onError);
      
      // Timeout after 5 seconds
      const timeoutId = setTimeout(() => {
        console.error('Audio load timeout');
        ghost.removeEventListener('canplay', onCanPlay);
        ghost.removeEventListener('error', onError);
        reject(new Error('Audio load timeout'));
      }, 5000);
    });
    
    // Ensure audio context is resumed (browser requirement)
    if (audioCtx && audioCtx.state === 'suspended') {
      await audioCtx.resume();
    }
    
    // Try to play the audio
    const playPromise = ghost.play();
    if (playPromise !== undefined) {
      await playPromise;
      await startVU();
      play.innerHTML = '<i class="bi-pause-fill"></i> Playing';
      play.classList.add('btn-success');
      updateStatus('Playing', f);
    }
    
  } catch (error) {
    console.error('Play error:', error);
    
    // Handle specific browser audio permission errors
    if (error.name === 'NotAllowedError') {
      alert('Please click the play button again to allow audio playback');
      // Reset button state
      play.innerHTML = '<i class="bi-play-fill"></i> Play';
      play.classList.remove('btn-success');
    } else {
      alert('Failed to play audio: ' + error.message);
    }
  } finally {
    play.disabled = false;
  }
};
stopBtn.onclick = async ()=>{
  try {
    stopBtn.disabled = true;
    const response = await fetch('/api/audio/stop', {method:'POST'});
    if (response.ok) {
      ghost.pause();
      ghost.currentTime = 0;
      play.innerHTML = '<i class="bi-play-fill"></i> Play';
      play.classList.remove('btn-success');
      if (audioCtx) {
        audioCtx.close();
        audioCtx = null;
        analyser = null;
        data = null;
      }
    }
  } catch (error) {
    console.error('Stop error:', error);
  } finally {
    stopBtn.disabled = false;
  }
};
vol.oninput = async e => {
  const volume = e.target.value;
  volVal.textContent = volume + '%';
  
  // Set volume on the audio element (works in cloud mode)
  ghost.volume = volume / 100;
  console.log('Audio volume set to:', ghost.volume);
  
  // Also try to set system volume (works on Linux/Unix, not Windows)
  try {
    const response = await fetch('/api/audio/volume/'+volume, {method:'POST'});
    if (response.ok) {
      const result = await response.json();
      if (result.mode === 'pi') {
        console.log('System volume set to:', volume + '%');
      } else {
        console.log('Using browser volume control (system volume not available)');
      }
    }
  } catch (error) {
    console.log('System volume control not available (using browser volume)');
  }
};

async function startVU(){
  try {
    // Check if audio element is already connected
    if (audioCtx && audioCtx.state !== 'closed') {
      console.log('Audio context already exists and active');
      return; // Don't recreate if already working
    }
    
    // Create new audio context only if needed
    if (!audioCtx || audioCtx.state === 'closed') {
      console.log('Creating new audio context');
      audioCtx = new (window.AudioContext||window.webkitAudioContext)();
      
      // Check if audio context is suspended and resume if needed
      if (audioCtx.state === 'suspended') {
        await audioCtx.resume();
        console.log('Audio context resumed');
      }
      
      const node = audioCtx.createMediaElementSource(ghost);
      analyser = audioCtx.createAnalyser(); 
      analyser.fftSize = 1024;
      data = new Uint8Array(analyser.frequencyBinCount);
      node.connect(analyser); 
      analyser.connect(audioCtx.destination);
      
      console.log('VU meter initialized, audio context state:', audioCtx.state);
    }
    
    draw();
  } catch (error) {
    console.error('VU meter setup failed:', error);
    // Continue without VU meter if it fails
  }
}
function draw(){
  requestAnimationFrame(draw); if(!analyser) return;
  analyser.getByteFrequencyData(data);
  const w = canvas.width = canvas.clientWidth, h = canvas.height = canvas.clientHeight;
  ctx.clearRect(0,0,w,h);
  const bars = 40, step = Math.floor(data.length/bars);
  for(let i=0;i<bars;i++){
    let s=0; for(let j=0;j<step;j++) s+=data[i*step+j];
    const v = (s/step)/255, bh = v*h;
    const x=(w/bars)*i+2, bw=(w/bars)-4;
    ctx.fillStyle = '#38bdf8'; ctx.fillRect(x, h-bh, bw, bh);
  }
}

// Voice Control System
const voiceInit = $('#voiceInit');
const voiceStart = $('#voiceStart');
const voiceStop = $('#voiceStop');
const voiceFeedback = $('#voiceFeedback');
const voiceTest = $('#voiceTest');
const voiceStatus = $('#voiceStatus');
const voiceListening = $('#voiceListening');
const voiceFeedbackStatus = $('#voiceFeedbackStatus');
const voiceCommands = $('#voiceCommands');
const lastCommand = $('#lastCommand');

let voiceActive = false;
let recognition = null;
let isListening = false;
let isPiMode = false;
let useBackendVoice = false;
let lastCommandTime = 0; // Track when last command was processed
let lastCommandText = ''; // Track the last command text

// Detect platform and capabilities
function detectPlatform() {
  const platform = navigator.platform || 'unknown';
  const userAgent = navigator.userAgent || '';
  
  console.log('Platform detection:', {
    platform: platform,
    userAgent: userAgent,
    hasWebSpeech: !!(window.SpeechRecognition || window.webkitSpeechRecognition),
    hasSpeechSynthesis: !!window.speechSynthesis
  });
  
  // Check if we're on Pi (Linux ARM) or should use backend
  if (platform.includes('Linux') || platform.includes('arm') || platform.includes('aarch64')) {
    isPiMode = true;
    useBackendVoice = true;
    console.log('🎯 Pi mode detected - using backend voice service');
  } else if (window.SpeechRecognition || window.webkitSpeechRecognition) {
    isPiMode = false;
    useBackendVoice = false;
    console.log('🖥️ Desktop mode detected - using Web Speech API');
  } else {
    isPiMode = false;
    useBackendVoice = true;
    console.log('🔄 Fallback mode - using backend voice service');
  }
  
  return { isPiMode, useBackendVoice };
}

// Set initial button states
voiceStart.disabled = true;
voiceStop.disabled = true;
voiceStart.classList.add('btn-outline-success');
voiceStart.classList.remove('btn-success');
voiceStop.classList.add('btn-outline-danger');
voiceStop.classList.remove('btn-danger');

console.log('🎤 Voice control buttons initialized with correct states');

// Initialize voice service
voiceInit.onclick = async () => {
  try {
    voiceInit.disabled = true;
    voiceStart.disabled = true; // Keep start button disabled during init
    voiceInit.innerHTML = '<i class="bi-hourglass-split"></i> Initializing...';
    
    // Detect platform and capabilities
    const { isPiMode, useBackendVoice } = detectPlatform();
    
    if (useBackendVoice) {
      // Use backend voice service (Pi mode or fallback)
      console.log('🎤 Initializing backend voice service...');
      
      const response = await fetch('/api/voice/init', { method: 'POST' });
      const result = await response.json();
      
      if (result.success && result.available) {
        voiceStatus.innerHTML = '<i class="bi-check-circle"></i> Backend Voice Ready';
        voiceStatus.style.color = '#28a745';
        voiceInit.innerHTML = '<i class="bi-check-circle"></i> Backend Voice Ready';
        voiceInit.disabled = false;
        
        // Enable the start listening button
        voiceStart.disabled = false;
        voiceStart.innerHTML = '<i class="bi-mic"></i> Start Listening';
        voiceStart.classList.remove('btn-outline-success');
        voiceStart.classList.add('btn-success');
        
        console.log('✅ Backend voice service ready - Start Listening button enabled');
      } else {
        throw new Error(result.message || 'Backend voice service not available');
      }
      
    } else {
      // Use frontend Web Speech API (Windows/Desktop)
      console.log('🎤 Initializing frontend voice recognition...');
      
      // Check if Web Speech API is available
      if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
        throw new Error('Web Speech API not supported in this browser');
      }
      
                     // Initialize frontend voice recognition
        recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
        recognition.continuous = true;
        recognition.interimResults = false; // Disable interim results to prevent loops
        recognition.lang = 'en-US';
        
        // Add noise filtering settings for Windows
        if (navigator.platform.indexOf('Win') !== -1) {
          // Make recognition more sensitive for testing
          recognition.maxAlternatives = 3; // Get multiple alternatives
          console.log('🪟 Windows: Using 3 alternatives for better recognition');
        }
      
      // Set up recognition event handlers
      recognition.onstart = () => {
        console.log('🎤 Voice recognition started');
        voiceStatus.innerHTML = '<i class="bi-check-circle"></i> Frontend Voice Ready';
        voiceStatus.style.color = '#28a745';
      };
      
                     recognition.onresult = (event) => {
          // Get all results including alternatives
          const results = Array.from(event.results);
          console.log('🎤 Voice results received:', results.length, 'results');
          
          // Only process final results to prevent loops
          for (let i = 0; i < results.length; i++) {
            const result = results[i];
            
            // Only process final results
            if (result.isFinal && result[0] && result[0].transcript) {
              const transcript = result[0].transcript;
              console.log('🎤 Final transcript found:', transcript);
              
              // Process the voice command
              handleVoiceCommand(transcript.toLowerCase().trim());
            } else {
              console.log('🔇 Skipping interim result:', result[0]?.transcript);
            }
          }
        };
      
      recognition.onerror = (event) => {
        console.error('Voice recognition error:', event.error);
        if (event.error === 'not-allowed') {
          voiceStatus.innerHTML = '<i class="bi-x-circle"></i> Microphone Access Denied';
          voiceStatus.style.color = '#dc3545';
        } else {
          voiceStatus.innerHTML = '<i class="bi-x-circle"></i> Recognition Error';
          voiceStatus.style.color = '#dc3545';
        }
      };
      
                     recognition.onend = () => {
          console.log('🎤 Voice recognition ended');
          // Force stop listening to prevent loops
          isListening = false;
          
          // Reset button states
          voiceStart.disabled = false;
          voiceStart.innerHTML = '<i class="bi-mic"></i> Start Listening';
          voiceStart.classList.remove('btn-warning');
          voiceStart.classList.add('btn-success');
          
          voiceStop.disabled = true;
          voiceStop.classList.remove('btn-danger');
          voiceStop.classList.add('btn-outline-danger');
          
          voiceListening.innerHTML = '<i class="bi-mic"></i> Not Listening';
          voiceListening.style.color = '#6c757d';
        };
      
      // Test the recognition system
      try {
        await recognition.start();
        await new Promise(resolve => setTimeout(resolve, 1000)); // Give it a second to start
        recognition.stop();
        
        voiceStatus.innerHTML = '<i class="bi-check-circle"></i> Frontend Voice Ready';
        voiceStatus.style.color = '#28a745';
        voiceInit.innerHTML = '<i class="bi-check-circle"></i> Frontend Voice Ready';
        voiceInit.disabled = false;
        
        // Enable the start listening button
        voiceStart.disabled = false;
        voiceStart.innerHTML = '<i class="bi-mic"></i> Start Listening';
        voiceStart.classList.remove('btn-outline-success');
        voiceStart.classList.add('btn-success');
        
        console.log('✅ Frontend voice recognition ready - Start Listening button enabled');
      } catch (error) {
        throw new Error('Failed to initialize voice recognition: ' + error.message);
      }
    }
    
  } catch (error) {
    console.error('Voice init error:', error);
    voiceStatus.innerHTML = '<i class="bi-x-circle"></i> ' + error.message;
    voiceStatus.style.color = '#dc3545';
    voiceInit.innerHTML = '<i class="bi-arrow-clockwise"></i> Retry';
    voiceInit.disabled = false;
    
    // Keep start button disabled
    voiceStart.disabled = true;
    voiceStart.innerHTML = '<i class="bi-mic-slash"></i> Not Available';
    voiceStart.classList.remove('btn-success');
    voiceStart.classList.add('btn-outline-secondary');
  }
};

voiceStart.onclick = async () => {
  try {
    voiceStart.disabled = true;
    voiceStart.innerHTML = '<i class="bi-hourglass-split"></i> Starting...';
    
    if (useBackendVoice) {
      // Start backend voice recognition
      console.log('🎤 Starting backend voice recognition...');
      
      const response = await fetch('/api/voice/start', { method: 'POST' });
      const result = await response.json();
      
      if (result.success) {
        // Update button states
        voiceStart.disabled = true;
        voiceStart.innerHTML = '<i class="bi-mic-fill"></i> Listening...';
        voiceStart.classList.remove('btn-success');
        voiceStart.classList.add('btn-warning');
        
        voiceStop.disabled = false;
        voiceStop.classList.remove('btn-outline-danger');
        voiceStop.classList.add('btn-danger');
        
        voiceListening.innerHTML = '<i class="bi-mic-fill"></i> Listening...';
        voiceListening.style.color = '#28a745';
        
        console.log('🎤 Backend voice recognition started - buttons updated');
      } else {
        throw new Error(result.message || 'Failed to start voice recognition');
      }
      
    } else {
      // Start frontend voice recognition
      if (!recognition) {
        throw new Error('Voice recognition not initialized');
      }
      
      console.log('🎤 Starting frontend voice recognition...');
      
             // Stop any existing recognition first
       if (recognition) {
         recognition.stop();
       }
       
       // Start fresh recognition
       recognition.start();
       isListening = true;
      
      // Update button states
      voiceStart.disabled = true;
      voiceStart.innerHTML = '<i class="bi-mic-fill"></i> Listening...';
      voiceStart.classList.remove('btn-success');
      voiceStart.classList.add('btn-warning');
      
      voiceStop.disabled = false;
      voiceStop.classList.remove('btn-outline-danger');
      voiceStop.classList.add('btn-danger');
      
      voiceListening.innerHTML = '<i class="bi-mic-fill"></i> Listening...';
      voiceListening.style.color = '#28a745';
      
      console.log('🎤 Frontend voice recognition started - buttons updated');
    }
    
    // Provide voice feedback
    speakText('Voice recognition started. I\'m listening for your commands.');
    
  } catch (error) {
    console.error('Voice start error:', error);
    alert('Failed to start voice recognition: ' + error.message);
    
    // Reset button state on error
    voiceStart.disabled = false;
    voiceStart.innerHTML = '<i class="bi-mic"></i> Start Listening';
    voiceStart.classList.remove('btn-warning');
    voiceStart.classList.add('btn-success');
  }
};

voiceStop.onclick = async () => {
  try {
    voiceStop.disabled = true;
    voiceStop.innerHTML = '<i class="bi-hourglass-split"></i> Stopping...';
    
    if (useBackendVoice) {
      // Stop backend voice recognition
      console.log('🎤 Stopping backend voice recognition...');
      
      const response = await fetch('/api/voice/stop', { method: 'POST' });
      const result = await response.json();
      
      if (result.success) {
        // Update button states
        voiceStart.disabled = false;
        voiceStart.innerHTML = '<i class="bi-mic"></i> Start Listening';
        voiceStart.classList.remove('btn-warning');
        voiceStart.classList.add('btn-success');
        
        voiceStop.disabled = true;
        voiceStop.classList.remove('btn-danger');
        voiceStop.classList.add('btn-outline-danger');
        
        voiceListening.innerHTML = '<i class="bi-mic"></i> Not Listening';
        voiceListening.style.color = '#6c757d';
        
        console.log('🔇 Backend voice recognition stopped - buttons updated');
      } else {
        throw new Error(result.message || 'Failed to stop voice recognition');
      }
      
    } else {
      // Stop frontend voice recognition
      console.log('🎤 Stopping frontend voice recognition...');
      
      if (recognition) {
        recognition.stop();
      }
      isListening = false;
      
      // Update button states
      voiceStart.disabled = false;
      voiceStart.innerHTML = '<i class="bi-mic"></i> Start Listening';
      voiceStart.classList.remove('btn-warning');
      voiceStart.classList.add('btn-success');
      
      voiceStop.disabled = true;
      voiceStop.classList.remove('btn-danger');
      voiceStop.classList.add('btn-outline-danger');
      
      voiceListening.innerHTML = '<i class="bi-mic"></i> Not Listening';
      voiceListening.style.color = '#6c757d';
      
      console.log('🔇 Frontend voice recognition stopped - buttons updated');
    }
    
    // Provide voice feedback
    speakText('Voice recognition stopped. I\'m no longer listening.');
    
  } catch (error) {
    console.error('Voice stop error:', error);
    alert('Failed to stop voice recognition: ' + error.message);
    
    // Reset button state on error
    voiceStop.disabled = false;
    voiceStop.innerHTML = '<i class="bi-mic-mute"></i> Stop Listening';
    voiceStop.classList.remove('btn-outline-danger');
    voiceStop.classList.add('btn-danger');
  }
};

// Toggle voice feedback
voiceFeedback.onclick = async () => {
  try {
    voiceFeedback.disabled = true;
    voiceFeedback.innerHTML = '<i class="bi-hourglass-split"></i> Toggling...';
    
    if (useBackendVoice) {
      // Use backend voice feedback toggle
      const response = await fetch('/api/voice/feedback/toggle', { method: 'POST' });
      const result = await response.json();
      
      if (result.success) {
        // Update the status display
        voiceFeedbackStatus.textContent = result.voiceFeedback ? 'Enabled' : 'Disabled';
        
        // Update the button text and icon
        voiceFeedback.innerHTML = result.voiceFeedback ? 
          '<i class="bi-volume-mute"></i> Disable Feedback' : 
          '<i class="bi-volume-up"></i> Enable Feedback';
        
        // Update button styling
        if (result.voiceFeedback) {
          voiceFeedback.classList.remove('btn-outline-info');
          voiceFeedback.classList.add('btn-info');
        } else {
          voiceFeedback.classList.remove('btn-info');
          voiceFeedback.classList.add('btn-outline-info');
        }
        
        console.log('✅ Backend voice feedback toggled:', result.message);
      } else {
        throw new Error(result.message || 'Failed to toggle voice feedback');
      }
    } else {
      // Toggle local voice feedback state
      const currentFeedback = voiceFeedbackStatus.textContent === 'Enabled';
      const newFeedback = !currentFeedback;
      
      // Update the status display
      voiceFeedbackStatus.textContent = newFeedback ? 'Enabled' : 'Disabled';
      
      // Update the button text and icon
      voiceFeedback.innerHTML = newFeedback ? 
        '<i class="bi-volume-mute"></i> Disable Feedback' : 
        '<i class="bi-volume-up"></i> Enable Feedback';
      
      // Update button styling
      if (newFeedback) {
        voiceFeedback.classList.remove('btn-outline-info');
        voiceFeedback.classList.add('btn-info');
      } else {
        voiceFeedback.classList.remove('btn-info');
        voiceFeedback.classList.add('btn-outline-info');
      }
      
      console.log('✅ Frontend voice feedback toggled:', newFeedback ? 'enabled' : 'disabled');
    }
    
    // Provide voice feedback about the change
    const feedbackMessage = voiceFeedbackStatus.textContent === 'Enabled' ? 
      'Voice feedback enabled. I will speak back to you.' : 
      'Voice feedback disabled. I will be quiet now.';
    speakText(feedbackMessage);
    
  } catch (error) {
    console.error('Voice feedback toggle error:', error);
    // Reset button state on error
    voiceFeedback.innerHTML = '<i class="bi-volume-up"></i> Toggle Feedback';
  } finally {
    voiceFeedback.disabled = false;
  }
};

// Test voice
voiceTest.onclick = async () => {
  try {
    voiceTest.disabled = true;
    voiceTest.innerHTML = '<i class="bi-hourglass-split"></i> Testing...';
    
    // Test the voice feedback by speaking a test message
    const testMessage = 'Voice control system is working. Hello from your BOOM box!';
    console.log('🎤 Test message:', testMessage);
    
    speakText(testMessage);
    
    console.log('✅ Text-to-speech test successful');
    alert('Voice test successful! You should hear the test message.');
    
  } catch (error) {
    console.error('Voice test error:', error);
    alert('Voice test failed: ' + error.message);
  } finally {
    voiceTest.disabled = false;
    voiceTest.innerHTML = '<i class="bi-chat"></i> Test Voice';
  }
};

// Reset voice recognition
const voiceReset = $('#voiceReset');
voiceReset.onclick = async () => {
  try {
    voiceReset.disabled = true;
    voiceReset.innerHTML = '<i class="bi-hourglass-split"></i> Resetting...';
    
    // Completely destroy the recognition object
    if (recognition) {
      try {
        recognition.stop();
        recognition.abort();
      } catch (e) {
        console.log('Recognition stop/abort error:', e);
      }
      recognition = null;
    }
    
    // Reset state variables
    isListening = false;
    lastCommandTime = 0;
    lastCommandText = '';
    
    // Reset button states
    voiceStart.disabled = false;
    voiceStart.innerHTML = '<i class="bi-mic"></i> Start Listening';
    voiceStart.classList.remove('btn-warning');
    voiceStart.classList.add('btn-success');
    
    voiceStop.disabled = true;
    voiceStop.classList.remove('btn-danger');
    voiceStop.classList.add('btn-outline-danger');
    
    voiceListening.innerHTML = '<i class="bi-mic"></i> Not Listening';
    voiceListening.style.color = '#6c757d';
    
    // Clear any ongoing speech
    if (window.speechSynthesis) {
      window.speechSynthesis.cancel();
    }
    
    console.log('✅ Voice recognition completely reset');
    speakText('Voice recognition has been completely reset');
    
  } catch (error) {
    console.error('Voice reset error:', error);
    alert('Voice reset failed: ' + error.message);
  } finally {
    voiceReset.disabled = false;
    voiceReset.innerHTML = '<i class="bi-arrow-clockwise"></i> Reset Voice';
  }
};

// Complete voice shutdown
const voiceShutdown = $('#voiceShutdown');
voiceShutdown.onclick = async () => {
  try {
    voiceShutdown.disabled = true;
    voiceShutdown.innerHTML = '<i class="bi-hourglass-split"></i> Shutting down...';
    
    // Completely destroy everything
    if (recognition) {
      try {
        recognition.stop();
        recognition.abort();
      } catch (e) {
        console.log('Recognition stop/abort error:', e);
      }
      recognition = null;
    }
    
    // Reset all state
    isListening = false;
    lastCommandTime = 0;
    lastCommandText = '';
    
    // Disable all voice buttons
    voiceStart.disabled = true;
    voiceStart.innerHTML = '<i class="bi-mic-slash"></i> Voice Disabled';
    voiceStart.classList.remove('btn-success', 'btn-warning');
    voiceStart.classList.add('btn-secondary');
    
    voiceStop.disabled = true;
    voiceStop.classList.remove('btn-danger');
    voiceStop.classList.add('btn-outline-secondary');
    
    voiceListening.innerHTML = '<i class="bi-mic-slash"></i> Voice Disabled';
    voiceListening.style.color = '#6c757d';
    
    // Clear any ongoing speech
    if (window.speechSynthesis) {
      window.speechSynthesis.cancel();
    }
    
    // Force stop any ongoing speech synthesis
    if (window.speechSynthesis) {
      window.speechSynthesis.pause();
      window.speechSynthesis.resume();
      window.speechSynthesis.cancel();
    }
    
    console.log('✅ Voice recognition completely shut down');
    alert('Voice recognition has been completely shut down. Refresh the page to re-enable.');
    
  } catch (error) {
    console.error('Voice shutdown error:', error);
    alert('Voice shutdown failed: ' + error.message);
  } finally {
    voiceShutdown.disabled = false;
    voiceShutdown.innerHTML = '<i class="bi-power"></i> Shutdown Voice';
  }
};

// Debug voice recognition
const voiceDebug = $('#voiceDebug');
voiceDebug.onclick = async () => {
  try {
    voiceDebug.disabled = true;
    voiceDebug.innerHTML = '<i class="bi-hourglass-split"></i> Debugging...';
    
    console.log('🐛 === VOICE RECOGNITION DEBUG ===');
    console.log('🎤 Recognition object:', recognition);
    console.log('🎤 Is listening:', isListening);
    console.log('🎤 Platform:', navigator.platform);
    console.log('🎤 User agent:', navigator.userAgent);
    console.log('🎤 Web Speech API available:', !!(window.SpeechRecognition || window.webkitSpeechRecognition));
    console.log('🎤 Speech synthesis available:', !!window.speechSynthesis);
    
    if (recognition) {
      console.log('🎤 Recognition state:', recognition.state || 'unknown');
      console.log('🎤 Recognition continuous:', recognition.continuous);
      console.log('🎤 Recognition interim results:', recognition.interimResults);
      console.log('🎤 Recognition max alternatives:', recognition.maxAlternatives);
      console.log('🎤 Recognition lang:', recognition.lang);
    }
    
    // Test microphone access
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      console.log('✅ Microphone access granted');
      stream.getTracks().forEach(track => track.stop());
    } catch (micError) {
      console.error('❌ Microphone access denied:', micError);
    }
    
         alert('Voice debug info logged to console. Check the browser console for details.');
     
   } catch (error) {
     console.error('Voice debug error:', error);
     alert('Voice debug failed: ' + error.message);
   } finally {
     voiceDebug.disabled = false;
     voiceDebug.innerHTML = '<i class="bi-bug"></i> Debug Voice';
   }
 };
 
 // Test pause functionality
 const pauseTest = $('#pauseTest');
 pauseTest.onclick = async () => {
   try {
     pauseTest.disabled = true;
     pauseTest.innerHTML = '<i class="bi-hourglass-split"></i> Testing...';
     
     console.log('🧪 Testing pause functionality...');
     console.log('🎵 Audio state - paused:', ghost.paused, 'readyState:', ghost.readyState, 'src:', ghost.src);
     
     if (ghost.src && ghost.src !== '' && !ghost.paused && ghost.readyState >= 2) {
       console.log('⏸️ Audio is playing, testing pause...');
       ghost.pause();
       play.innerHTML = '<i class="bi-play-fill"></i> Play';
       play.classList.remove('btn-success');
       updateStatus('Paused', file.value);
       speakText('Pause test successful - music paused');
     } else if (ghost.paused && ghost.src && ghost.src !== '') {
       console.log('▶️ Audio is paused, testing resume...');
       ghost.play();
       play.innerHTML = '<i class="bi-pause-fill"></i> Playing';
       play.classList.add('btn-success');
       updateStatus('Playing', file.value);
       speakText('Resume test successful - music playing');
     } else {
       console.log('⚠️ Audio not ready for pause test');
       speakText('No music ready for pause test. Please play music first.');
     }
     
   } catch (error) {
     console.error('Pause test error:', error);
     speakText('Pause test failed: ' + error.message);
   } finally {
     pauseTest.disabled = false;
     pauseTest.innerHTML = '<i class="bi-pause"></i> Test Pause';
   }
 };

// Function to validate voice commands - ultra permissive for testing
function isValidVoiceCommand(transcript) {
  const cleanCommand = transcript.toLowerCase().trim();
  
  // Log everything for debugging
  console.log('🔍 Raw transcript:', transcript);
  console.log('🔍 Clean command:', cleanCommand);
  console.log('🔍 Command length:', cleanCommand.length);
  
  // Ultra permissive - accept ANYTHING that's not empty
  if (cleanCommand.length < 1) {
    console.log('❌ Empty command, rejecting');
    return false;
  }
  
  // Accept everything for now to debug the issue
  console.log('✅ Accepting all commands for debugging');
  return true;
}

// Function to speak text using browser's built-in speech synthesis or backend
function speakText(text) {
  try {
    // Check if voice feedback is enabled
    if (voiceFeedbackStatus.textContent === 'Disabled') {
      console.log('Voice feedback disabled, not speaking:', text);
      return;
    }
    
    if (useBackendVoice) {
      // Use backend text-to-speech (Pi mode)
      console.log('🎤 Using backend text-to-speech:', text);
      fetch('/api/voice/speak', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ text })
      }).catch(error => {
        console.error('Backend speak error:', error);
        // Fallback to console log
        console.log('🎤 Voice feedback (fallback):', text);
      });
    } else {
      // Use browser's built-in speech synthesis (Windows/Desktop)
      if ('speechSynthesis' in window) {
        // Cancel any ongoing speech
        window.speechSynthesis.cancel();
        
        // Create a new speech utterance
        const utterance = new SpeechSynthesisUtterance(text);
        utterance.lang = 'en-US';
        utterance.rate = 0.9;
        utterance.pitch = 1.0;
        utterance.volume = 0.8;
        
        // Speak the text
        window.speechSynthesis.speak(utterance);
        console.log('🎤 Browser speech synthesis:', text);
      } else {
        console.log('🎤 Speech synthesis not available, using console fallback:', text);
      }
    }
  } catch (error) {
    console.error('Speech synthesis error:', error);
    console.log('🎤 Voice feedback fallback:', text);
  }
}

// Handle voice commands from server - simplified and working
async function handleVoiceCommand(command) {
  console.log('🎤 Voice command received:', command);
  console.log('🎤 Command length:', command.length);
  console.log('🎤 Command contains "pause":', command.toLowerCase().includes('pause'));
  console.log('🎤 Command contains "stop":', command.toLowerCase().includes('stop'));
  
  // Check if this is a duplicate command (same text within 10 seconds)
  const now = Date.now();
  const timeSinceLastCommand = now - lastCommandTime;
  const isDuplicate = (command.toLowerCase().trim() === lastCommandText && timeSinceLastCommand < 10000);
  
  if (isDuplicate) {
    console.log('🔇 Duplicate command ignored:', command);
    return; // Don't process duplicate commands
  }
  
  // Update tracking variables
  lastCommandTime = now;
  lastCommandText = command.toLowerCase().trim();
  
  // Show command in UI
  lastCommand.textContent = command;
  voiceCommands.style.display = 'block';
  
  // Hide command display after 3 seconds
  setTimeout(() => {
    voiceCommands.style.display = 'none';
  }, 3000);
  
  // If using backend voice, send command to backend for processing
  if (useBackendVoice) {
    try {
      await fetch('/api/voice/frontend-command', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ command })
      });
    } catch (error) {
      console.error('Failed to send command to backend:', error);
    }
  }
  
  // Simple command detection - no complex logic
  const cleanCommand = command.toLowerCase().trim();
  
  // Basic commands
     if (cleanCommand.includes('play')) {
     console.log('🎵 Voice command: Playing music');
     // Don't speak here to prevent loops - just play the music
    
    // Auto-select file if none selected
    if (!file.value || file.value === '— files will appear here —') {
      const fileSelect = document.getElementById('fileSelect');
      if (fileSelect.options.length > 1) {
        fileSelect.selectedIndex = 1;
        file.value = fileSelect.value;
        console.log('🎵 Auto-selected file:', file.value);
      } else {
        speakText('No music files available');
        return;
      }
    }
    
    // Play the music
    await playAudioFromVoice();
    
        } else if (cleanCommand.includes('pause') || cleanCommand.includes('paws')) {
      console.log('⏸️ Voice command: Pausing music');
      console.log('🎵 Current audio state - paused:', ghost.paused, 'readyState:', ghost.readyState, 'src:', ghost.src);
      
             // Check if audio is actually playing (has source and is not paused)
       if (ghost.src && ghost.src !== '' && !ghost.paused && ghost.readyState >= 2) {
         console.log('⏸️ Audio is playing, pausing it');
         ghost.pause();
         play.innerHTML = '<i class="bi-play-fill"></i> Play';
         play.classList.remove('btn-success');
         updateStatus('Paused', file.value);
         // Don't speak here to prevent loops
       } else if (ghost.paused && ghost.src && ghost.src !== '') {
         console.log('▶️ Audio is paused, resuming it');
         ghost.play();
         play.innerHTML = '<i class="bi-pause-fill"></i> Playing';
         play.classList.add('btn-success');
         updateStatus('Playing', file.value);
         // Don't speak here to prevent loops
       } else {
         console.log('⚠️ Audio not ready or no source');
         // Don't speak here to prevent loops
       }
     
        } else if (cleanCommand.includes('resume') || cleanCommand.includes('continue')) {
       console.log('▶️ Voice command: Resuming music');
       if (ghost.paused === true && ghost.readyState >= 2) {
         console.log('▶️ Audio is paused, resuming it');
         ghost.play();
         play.innerHTML = '<i class="bi-pause-fill"></i> Playing';
         play.classList.add('btn-success');
         updateStatus('Playing', file.value);
         // Don't speak here to prevent loops
       } else {
         console.log('⚠️ Audio not paused or not ready');
         // Don't speak here to prevent loops
       }
     
       } else if (cleanCommand.includes('stop') || cleanCommand.includes('stahp')) {
      console.log('⏹️ Voice command: Stopping music');
      ghost.pause();
      ghost.currentTime = 0;
      play.innerHTML = '<i class="bi-play-fill"></i> Play';
      play.classList.remove('btn-success');
      updateStatus('Stopped', file.value);
      // Don't speak here to prevent loops - just stop the music
    
  } else if (cleanCommand.includes('volume') || cleanCommand.includes('vol')) {
    if (cleanCommand.includes('up')) {
      const newVol = Math.min(100, parseInt(vol.value) + 10);
      vol.value = newVol;
      volVal.textContent = newVol + '%';
      ghost.volume = newVol / 100;
      vol.dispatchEvent(new Event('input'));
      speakText(`Volume increased to ${newVol} percent`);
    } else if (cleanCommand.includes('down')) {
      const newVol = Math.max(0, parseInt(vol.value) - 10);
      vol.value = newVol;
      volVal.textContent = newVol + '%';
      ghost.volume = newVol / 100;
      vol.dispatchEvent(new Event('input'));
      speakText(`Volume decreased to ${newVol} percent`);
    }
    
  } else if (cleanCommand.includes('song') || cleanCommand.includes('what')) {
    const currentSong = file.value || 'No song selected';
    speakText(`Currently playing: ${currentSong}`);
    
  } else if (cleanCommand.includes('help')) {
    speakText('Available commands: play, pause, stop, volume up, volume down, what song, and help');
    
     } else if (cleanCommand.includes('test')) {
     speakText('Voice command system is working!');
     
   } else {
     console.log('❌ Command not recognized:', command);
     console.log('🔍 Full command analysis:');
     console.log('  - Raw command:', command);
     console.log('  - Clean command:', cleanCommand);
     console.log('  - Contains "play":', cleanCommand.includes('play'));
     console.log('  - Contains "pause":', cleanCommand.includes('pause'));
     console.log('  - Contains "stop":', cleanCommand.includes('stop'));
     console.log('  - Contains "volume":', cleanCommand.includes('volume'));
     // Don't speak for unrecognized commands to avoid loops
     // speakText(`I didn't understand "${command}". Try saying "play" or "help"`);
   }
}

// Helper function to play audio from voice command
async function playAudioFromVoice() {
  const f = file.value; 
  if(!f || f === '— files will appear here —') {
    console.log('No file selected for voice play command');
    return;
  }
  
  console.log('Voice command: Attempting to play:', f);
  
  try {
    // Always set new source for new file (prevents caching issues)
    const newSrc = `/api/audio/stream/${encodeURIComponent(f)}`;
    console.log('Setting new source from voice command:', newSrc);
    ghost.src = newSrc;
    updateStatus('Loading...', f);
    
    // Reset audio state
    ghost.currentTime = 0;
    
    // Wait for audio to be ready
    await new Promise((resolve, reject) => {
      const onCanPlay = () => {
        console.log('Audio can play from voice command, readyState:', ghost.readyState);
        ghost.removeEventListener('canplay', onCanPlay);
        ghost.removeEventListener('error', onError);
        clearTimeout(timeoutId);
        resolve();
      };
      
      const onError = (error) => {
        console.error('Audio load error from voice command:', error);
        ghost.removeEventListener('canplay', onCanPlay);
        ghost.removeEventListener('error', onError);
        clearTimeout(timeoutId);
        reject(error);
      };
      
      ghost.addEventListener('canplay', onCanPlay);
      ghost.addEventListener('error', onError);
      
      // Timeout after 5 seconds
      const timeoutId = setTimeout(() => {
        console.error('Audio load timeout from voice command');
        ghost.removeEventListener('canplay', onCanPlay);
        ghost.removeEventListener('error', onError);
        reject(new Error('Audio load timeout'));
      }, 5000);
    });
    
    // Ensure audio context is resumed (browser requirement)
    if (audioCtx && audioCtx.state === 'suspended') {
      await audioCtx.resume();
    }
    
    // Try to play the audio with better Windows compatibility
    try {
      const playPromise = ghost.play();
      if (playPromise !== undefined) {
        await playPromise;
        await startVU();
        play.innerHTML = '<i class="bi-pause-fill"></i> Playing';
        play.classList.add('btn-success');
        updateStatus('Playing', f);
                 console.log('✅ Voice command play successful');
         // Don't speak here to prevent loops - just play the music
      }
    } catch (playError) {
      console.error('Play promise error:', playError);
      
      // Try alternative approach for Windows
      if (playError.name === 'NotAllowedError' || playError.name === 'AbortError') {
        console.log('Trying alternative play method for Windows...');
        
                 // Force play with user interaction simulation
         ghost.play().then(() => {
           console.log('✅ Alternative play method successful');
           play.innerHTML = '<i class="bi-pause-fill"></i> Playing';
           play.classList.add('btn-success');
           updateStatus('Playing', f);
           // Don't speak here to prevent loops
         }).catch((altError) => {
          console.error('Alternative play method failed:', altError);
          speakText('Failed to play music. Please check audio permissions.');
        });
      } else {
        throw playError;
      }
    }
    
  } catch (error) {
    console.error('Voice command play error:', error);
    
    // Handle specific browser audio permission errors
    if (error.name === 'NotAllowedError') {
      console.log('Audio permission denied for voice command');
      speakText('Audio permission denied. Please allow audio playback in your browser.');
    } else {
      console.error('Failed to play audio from voice command:', error.message);
      speakText('Failed to play music. Please try again.');
    }
  }
}

// Add debug info
console.log('Player initialized');
console.log('Audio element:', ghost);
console.log('Initial volume:', ghost.volume);

// Windows-specific audio fixes
if (navigator.platform.indexOf('Win') !== -1) {
  console.log('🪟 Windows platform detected - applying audio fixes');
  
  // Ensure audio context is created and resumed
  if (audioCtx) {
    audioCtx.resume().then(() => {
      console.log('✅ Audio context resumed for Windows');
    }).catch(err => {
      console.log('⚠️ Audio context resume failed:', err);
    });
  }
  
  // Add Windows-specific audio event handlers
  ghost.addEventListener('loadstart', () => {
    console.log('🪟 Windows: Audio load started');
  });
  
  ghost.addEventListener('canplaythrough', () => {
    console.log('🪟 Windows: Audio can play through');
  });
}

// Test audio element
ghost.addEventListener('loadedmetadata', () => {
  console.log('Audio metadata loaded');
  console.log('Duration:', ghost.duration);
  console.log('Current volume:', ghost.volume);
});

ghost.addEventListener('canplay', () => {
  console.log('Audio can play');
});

ghost.addEventListener('error', (e) => {
  console.error('Audio error:', e);
  console.error('Error details:', ghost.error);
});

// Initialize Socket.IO connection
initSocketIO();

loadFiles();
 
 // Update footer date
 function updateFooterDate() {
   const today = new Date();
   const options = { 
     year: 'numeric', 
     month: 'long', 
     day: 'numeric' 
   };
   const dateString = today.toLocaleDateString('en-US', options);
   document.getElementById('currentDate').textContent = dateString;
 }
 
 // Set the date when page loads
 updateFooterDate();
 </script>
 </body>
</html>